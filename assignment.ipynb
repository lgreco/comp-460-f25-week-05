{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7e50023",
   "metadata": {},
   "source": [
    "# Implementing a Multilayer Perceptron\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630dca2e",
   "metadata": {},
   "source": [
    "![](/workspaces/comp-460-f25-week-05/images/XOR.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22ce30c",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "  a^2_1 & = \\sigma( w^2_{11} x_1 + w^2_{12} x_2 + b^2_1 ) \\\\ & =\n",
    "  \\sigma\\left(\n",
    "    \\begin{bmatrix} w^2_{11} & w^2_{12}\\end{bmatrix} \\cdot\n",
    "    \\begin{bmatrix}x_1 \\\\ x_2\\end{bmatrix} + b^2_1 \\right) \\\\ &=\n",
    "    \\sigma\\left( \\mathbf w^2_1\\cdot\\mathbf x + b^2_1\\right) \\\\ \\\\\n",
    "\n",
    "  a^2_2 & = \\sigma\\left( \\mathbf w^2_2\\cdot\\mathbf x + b^2_2 \\right) \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\n",
    "  \\begin{bmatrix}a^2_1 \\\\ \\\\a^2_2 \\end{bmatrix} & =\n",
    "  \\sigma \\left(\n",
    "    \\begin{bmatrix}\\mathbf w^2_1 \\\\ \\\\ \\mathbf w^2_2 \\end{bmatrix} \\cdot\\mathbf x +\n",
    "    \\begin{bmatrix}b^2_1 \\\\ \\\\ b^2_2 \\end{bmatrix}\n",
    "  \\right) \\Rightarrow \\\\ \\\\\n",
    "  \\mathbf a^2 & = \\sigma \\left(\\mathbf w^2 \\cdot \\mathbf x + \\mathbf b^2 \\right) \\\\\n",
    "  & = \\sigma\\left(\\mathbf z^2\\right)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "As we compact the notation, $\\mathbf a^2$ is the output vector for the hidden layer in response to $\\mathbf z^2=\\mathbf w^2 \\cdot \\mathbf x + \\mathbf b^2 $.\n",
    "Matrix $\\mathbf w^2$ contains the input weights for that layer.\n",
    "\n",
    "$$\n",
    "\\mathbf w^2 =\n",
    "\\begin{bmatrix}\n",
    "  w^2_{11} & w^2_{12} \\\\\n",
    "  w^2_{21} & w^2_{22}\n",
    "\\end{bmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68b275c",
   "metadata": {},
   "source": [
    "For the neuron in the third layer, the output is\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "a^3_1 & = \\sigma \\left( a^2_1 w^3_{11} + a^2_2 w^3_{12} +b^3_1 \\right) \\\\\n",
    "      & = \\sigma \\left( \\mathbf a^2 \\cdot \\mathbf w^3 + b^3_1 \\right) \\\\\n",
    "      & = \\sigma \\left( \\sigma(\\mathbf z^2) \\cdot \\mathbf w^3 + b^3_1 \\right) \\\\\n",
    "      & =  \\sigma \\left( \\sigma(\\mathbf w^2 \\cdot \\mathbf x + \\mathbf b^2) \\cdot \\mathbf w^3 + b^3_1 \\right)\n",
    "      &\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "In vector form, $\\mathbf a^3 = \\sigma \\left( \\sigma\\left(\\mathbf w^2 \\cdot \\mathbf x + \\mathbf b^2\\right) \\cdot \\mathbf w^3 + \\mathbf b^3 \\right)$,\n",
    "where $\\mathbf a^3 = \\begin{bmatrix} a^3_1 \\end{bmatrix}$ and $\\mathbf b^3 = \\begin{bmatrix} b^3_1 \\end{bmatrix}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa4548e",
   "metadata": {},
   "source": [
    "Consider the following weights and biases for the second and third layers:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\mathbf w^2 &= \\begin{bmatrix} 20 & 20 \\\\ -20 & -20  \\end{bmatrix}\\qquad\n",
    "& \\mathbf w^3 &= \\begin{bmatrix} 20 & 20  \\end{bmatrix}  \\\\\n",
    "\\mathbf b^2 &= \\begin{bmatrix}  -10 \\\\ 30  \\end{bmatrix} \\qquad\n",
    "& \\mathbf b^3 &= \\begin{bmatrix} -30  \\end{bmatrix}\n",
    "\\end{align*}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df723506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "a  b   mystery\n",
      "-------------\n",
      "0  0     0\n",
      "0  1     1\n",
      "1  0     1\n",
      "1  1     0\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "# Sigmoid activation\n",
    "def sigmoid(z: float) -> float:\n",
    "    return 1 / (1 + math.exp(-z))\n",
    "\n",
    "\n",
    "# Forward pass through fixed weights\n",
    "def mystery(x1: int, x2: int) -> int:\n",
    "    # Hard-coded weights for hidden layer (2 neurons)\n",
    "\n",
    "    w2 = [[20, 20], [-20, -20]]  # neuron 1  # neuron 2\n",
    "    b2 = [-10, 30]  # biases for hidden neurons\n",
    "\n",
    "    # Hidden activations\n",
    "    hidden = []\n",
    "    for j in range(2):\n",
    "        z = w2[j][0] * x1 + w2[j][1] * x2 + b2[j]\n",
    "        hidden.append(sigmoid(z))\n",
    "\n",
    "    # Output neuron combines them: essentially hidden[0] - hidden[1]\n",
    "    w3 = [20, 20]\n",
    "    b3 = -30\n",
    "\n",
    "    z_out = w3[0] * hidden[0] + w3[1] * hidden[1] + b3\n",
    "    output = sigmoid(z_out)\n",
    "\n",
    "    return round(output)  # round to 0 or 1\n",
    "\n",
    "\n",
    "# Test XOR\n",
    "print(f\"\\na  b   mystery\\n-------------\")\n",
    "for a in [0, 1]:\n",
    "    for b in [0, 1]:\n",
    "        print(f\"{a}  {b}     {mystery(a,b)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90df8129",
   "metadata": {},
   "source": [
    "# Your assignment\n",
    "\n",
    "# Reading\n",
    "\n",
    "- **PDF:** [An algorithm for the machine calculation of complex Fourier series](https://www.ams.org/mcom/1965-19-090/S0025-5718-1965-0178586-1/S0025-5718-1965-0178586-1.pdf): the original paper on FFT by Cooley and Tukey.\n",
    "\n",
    "- **PDF:** [The Design and Implementation of FFTW3](http://fftw.org/fftw-paper-ieee.pdf) discusses why faster algorithms some times slow down a bit.\n",
    "\n",
    "- **PDF:** [FFT material](https://jeffe.cs.illinois.edu/teaching/algorithms/notes/A-fft.pdf) from Jeff Erickson's book. As much as I like Jeff's book, I think this chapter is a bit dense or scattered. With patience, you may find good information but it's not an easy read.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938786b2",
   "metadata": {},
   "source": [
    "## The sigmoid function\n",
    "\n",
    "The sigmoid function\n",
    "\n",
    "$$\n",
    "\\sigma(z) = \\frac{1}{1+e^{-z}}\n",
    "$$\n",
    "\n",
    "is a smoother function that has similar behavior to the step function. For large values of $z$, $\\sigma(z) \\rightarrow 1$ (and for small values of $z$, $\\sigma(z) \\rightarrow 0$). For any value inbetween, $\\sigma(z)$ has a smoother behavior that the step function and, more importantly, can be differentiated:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{d}{dz}\\sigma(z) = \\sigma(z)\\left(1-\\sigma(z)\\right)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "The derivative above is obtained with the chain rule for $\\sigma(z) = f(u(z))$ where $u(z) = 1+e^{-z}$ and $f(u) = u^{-1}$:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{d}{dz}\\sigma(z) & = \\frac{d}{dz} f(u(z)) \\\\\n",
    "   & = \\frac{df}{du}\\frac{du}{dz} \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "with $df/du = -u^{-2}$ and $du/dz = -e^{z}$, so that\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "  \\frac{df}{du}\\frac{du}{dz} & = (-(1+e^{-z}))^{-2} (-e^{-z}) \\\\\n",
    "                             & = \\frac{e^{-z}}{(1+e^{-z})^{-2}} \\\\\n",
    "                             & = \\left(\\frac{1}{1+e^{-z}}\\right) \\left(\\frac{e^{-z}}{1+e^{-z}}\\right) \\\\\n",
    "                             &  = \\left(\\frac{1}{1+e^{-z}}\\right)   \\left(\\frac{1+e^{-z}-1}{1+e^{-z}}\\right) \\\\\n",
    "                            &  = \\left(\\frac{1}{1+e^{-z}}\\right)   \\left(\\frac{1+e^{-z}}{1+e^{-z}}-\\frac{1}{1+e^{-z}}\\right) \\\\\n",
    "                            & =  \\left(\\frac{1}{1+e^{-z}}\\right)   \\left(1-\\frac{1}{1+e^{-z}}\\right) \\\\\n",
    "                            & = \\sigma(z)(1-\\sigma(z))\n",
    "\\end{align*}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd4dce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def sigmoid(z: float) -> float:\n",
    "    return 1 / (1 + math.exp(-z))\n",
    "\n",
    "\n",
    "def sigmoid_derivative(z: float) -> float:\n",
    "    s = sigmoid(z)\n",
    "    return s * (1 - s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
